import os, sys, base64, zlib

# Tissaia Project - Compact Installer
# Generated by Gemini Architect

def w(path, content):
    d = os.path.dirname(path)
    if d and not os.path.exists(d): os.makedirs(d)
    with open(path, 'w', encoding='utf-8') as f: f.write(content.strip())
    print(f"[+] {path}")

def main():
    base = "Tissaia_Project"
    
    # 1. DEPENDENCIES
    w(f"{base}/requirements.txt", """requests>=2.31.0\npython-dotenv>=1.0.0\nPillow>=10.0.0\nnumpy>=1.24.0""")
    w(f"{base}/.env.example", "GOOGLE_API_KEY=Put_Your_Key_Here")
    
    # 2. CONFIG
    w(f"{base}/src/__init__.py", "")
    w(f"{base}/src/config.py", """
import os
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.environ.get("GOOGLE_API_KEY")
if not API_KEY: print("WARN: No API Key"); exit(1)
MODEL_DETECTION = "models/gemini-1.5-pro"
MODEL_RESTORATION = "models/gemini-1.5-pro"
MAX_WORKERS = 20
INPUT_ZIP = "zdjecia.zip"
OUTPUT_DIR = "odnowione_final"
TEMP_DIR = "temp_input"
""")

    # 3. UTILS
    w(f"{base}/src/utils.py", """
import time, random, io, base64, requests
from PIL import Image
def encode_image_optimized(path, max_size=3500, quality=93):
    with Image.open(path) as img:
        if img.mode != "RGB": img = img.convert("RGB")
        if max(img.size) > max_size: img.thumbnail((max_size, max_size))
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=quality)
        return base64.b64encode(buf.getvalue()).decode('utf-8')

def make_request_with_retry(url, json_payload, headers, max_retries=10):
    for i in range(max_retries):
        try:
            r = requests.post(url, json=json_payload, headers=headers, timeout=600)
            if r.status_code == 404: return r
            if r.status_code in [429, 500, 503]:
                time.sleep((i + 1) * 2 + random.randint(1, 5))
                continue
            return r
        except: time.sleep(2)
    return None
""")

    # 4. GRAPHICS
    w(f"{base}/src/graphics.py", """
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageChops

def aggressive_trim_borders(img):
    try:
        bg = Image.new(img.mode, img.size, img.getpixel((0,0)))
        diff = ImageChops.difference(img, bg)
        diff = ImageChops.add(diff, diff, 2.0, -100)
        bbox = diff.getbbox()
        if bbox and (bbox[2]-bbox[0]) > 50 and (bbox[3]-bbox[1]) > 50: return img.crop(bbox)
    except: pass
    return img

def apply_super_sharpen(img):
    img = ImageEnhance.Sharpness(img).enhance(1.5)
    return img.filter(ImageFilter.UnsharpMask(radius=3, percent=150, threshold=3))

def warp_perspective(img, corners):
    def find_coeffs(pa, pb):
        matrix = []
        for p1, p2 in zip(pa, pb):
            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p1[0]*p2[0], -p1[0]*p2[1]])
            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p1[1]*p2[0], -p1[1]*p2[1]])
        A = np.matrix(matrix, dtype=float)
        B = np.array(pb).reshape(8)
        try: return np.array(np.dot(np.linalg.inv(A.T * A) * A.T, B)).reshape(8)
        except: return None

    pts = np.array(corners, dtype="float32")
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1)
    tl, br = pts[np.argmin(s)], pts[np.argmax(s)]
    tr, bl = pts[np.argmin(diff)], pts[np.argmax(diff)]
    
    wA = np.sqrt(((br[0]-bl[0])**2) + ((br[1]-bl[1])**2))
    wB = np.sqrt(((tr[0]-tl[0])**2) + ((tr[1]-tl[1])**2))
    mw = max(int(wA), int(wB))
    hA = np.sqrt(((tr[0]-br[0])**2) + ((tr[1]-br[1])**2))
    hB = np.sqrt(((tl[0]-bl[0])**2) + ((tl[1]-bl[1])**2))
    mh = max(int(hA), int(hB))

    coeffs = find_coeffs([(0,0), (mw,0), (mw,mh), (0,mh)], [(tl[0],tl[1]), (tr[0],tr[1]), (br[0],br[1]), (bl[0],bl[1])])
    if coeffs is not None: return img.transform((mw, mh), Image.PERSPECTIVE, coeffs, Image.BICUBIC)
    return img
""")

    # 5. AI CORE
    w(f"{base}/src/ai_core.py", """
import json, re, io, base64
from PIL import Image
from src.config import API_KEY, MODEL_DETECTION, MODEL_RESTORATION
from src.utils import make_request_with_retry, encode_image_optimized
from src.graphics import aggressive_trim_borders, apply_super_sharpen

def get_url(m): return f"https://generativelanguage.googleapis.com/v1beta/models/{m.replace('models/','')}:generateContent"

def detect_rotation_strict(path):
    # Semantyczna detekcja: Gdzie jest gora glowy?
    url = get_url(MODEL_DETECTION)
    try:
        with Image.open(path) as img:
            img.thumbnail((800,800))
            buf=io.BytesIO(); img.save(buf,format="JPEG"); b64=base64.b64encode(buf.getvalue()).decode('utf-8')
        p = "Look at people. Task: Direction of TOP OF HEADS? Options: 'UP','DOWN','LEFT','RIGHT'. JSON: {\\"direction\\": \\"UP\\"}"
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"responseMimeType":"application/json"}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        if r and r.status_code==200:
            d = json.loads(r.json()["candidates"][0]["content"]["parts"][0]["text"]).get("direction","UP")
            return {"UP":0, "DOWN":180, "RIGHT":90, "LEFT":270}.get(d, 0)
    except: pass
    return 0

def detect_corners(path):
    url = get_url(MODEL_DETECTION)
    try:
        b64 = encode_image_optimized(path, 1500)
        p = "Analyze scan. Detect 4 EXACT CORNERS. JSON: {\\"photos\\": [{\\"corners\\":[[x,y],[x,y],[x,y],[x,y]]}]}. Scale 0-1000."
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"responseMimeType":"application/json"}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        if r and r.status_code==200:
            return json.loads(re.sub(r"```json|```","", r.json()["candidates"][0]["content"]["parts"][0]["text"]).strip())
    except: pass
    return None

def restore_final(path, out):
    url = get_url(MODEL_RESTORATION)
    try:
        b64 = encode_image_optimized(path, 4000)
        p = "Restore photo: Fix geometry (inpaint corners), remove flash glare/dust, sharpen faces, natural skin. Full image, no borders."
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"temperature":0.35}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        if r and r.status_code==200:
            data = r.json()
            if "candidates" in data:
                raw = data["candidates"][0]["content"]["parts"]
                for x in raw:
                    if "inlineData" in x:
                        img = Image.open(io.BytesIO(base64.b64decode(x["inlineData"]["data"])))
                        img = apply_super_sharpen(aggressive_trim_borders(img))
                        img.save(out)
                        return True
    except: pass
    return False
""")

    # 6. WORKFLOW
    w(f"{base}/src/workflow.py", """
import os, random
from PIL import Image
from src.config import OUTPUT_DIR
from src.ai_core import detect_rotation_strict, detect_corners, restore_final
from src.graphics import warp_perspective

def process(fpath, fname):
    log = []
    temps = []
    try:
        # Rotacja
        ang = detect_rotation_strict(fpath)
        cur = fpath
        if ang != 0:
            cur = f"tmp_rot_{random.randint(111,999)}_{fname}"
            Image.open(fpath).rotate(ang, expand=True).save(cur)
            temps.append(cur)
        
        # Wycinanie
        data = detect_corners(cur)
        parts = []
        if data and "photos" in data:
            img = Image.open(cur).convert("RGB")
            w, h = img.size
            for i, item in enumerate(data["photos"]):
                try:
                    px = [[(p[0]/1000)*w, (p[1]/1000)*h] for p in item["corners"]]
                    s = warp_perspective(img, px)
                    if s:
                        n = f"tmp_cut_{i}_{fname}"
                        s.save(n, quality=95)
                        parts.append(n); temps.append(n)
                except: pass
        if not parts: parts.append(cur)
        
        # Renowacja
        for i, p in enumerate(parts):
            suf = f"_{i+1}" if len(parts)>1 else ""
            out = os.path.join(OUTPUT_DIR, f"restored_{os.path.splitext(fname)[0]}{suf}.png")
            if os.path.exists(out): log.append(f"SKIP: {out}"); continue
            
            print(f">> Processing {fname} part {i+1}")
            if restore_final(p, out): log.append(f"OK: {out}")
            else: log.append(f"ERR: {fname}")
            
    except Exception as e: log.append(f"CRASH {fname}: {e}")
    finally:
        for t in temps: 
            if os.path.exists(t): os.remove(t)
    return log
""")

    # 7. MAIN
    w(f"{base}/main.py", """
import os, zipfile, shutil, concurrent.futures
from src.config import INPUT_ZIP, OUTPUT_DIR, TEMP_DIR, MAX_WORKERS
from src.workflow import process

if __name__ == "__main__":
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
    os.makedirs(TEMP_DIR)
    
    if not os.path.exists(INPUT_ZIP): print("No zip!"); exit()
    with zipfile.ZipFile(INPUT_ZIP,'r') as z: z.extractall(TEMP_DIR)
    
    fs = [os.path.join(r,f) for r,_,x in os.walk(TEMP_DIR) for f in x if f.lower().endswith(('jpg','png','jpeg'))]
    print(f"Start: {len(fs)} files, {MAX_WORKERS} threads.")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        ft = {ex.submit(process, f, os.path.basename(f)):f for f in fs}
        for f in concurrent.futures.as_completed(ft):
            for l in f.result(): print(l)
            
    try: shutil.rmtree(TEMP_DIR)
    except: pass
    print("DONE.")
""")

    print(f"\\n[+] Generated project in '{base}'. Run 'pip install -r requirements.txt' then 'python main.py'")

if __name__ == "__main__":
    main()
