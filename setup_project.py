import os, sys, base64, zlib

# Tissaia Project - Installer V7 (Gemini 3 Engine)
# Generated by Gemini Architect & The Warlord

def w(path, content):
    d = os.path.dirname(path)
    if d and not os.path.exists(d): os.makedirs(d)
    with open(path, 'w', encoding='utf-8') as f: f.write(content.strip())
    print(f"[+] {path}")

def main():
    base = "Tissaia_Project"
    
    # 1. DEPENDENCIES
    w(f"{base}/requirements.txt", """requests>=2.31.0
python-dotenv>=1.0.0
Pillow>=10.0.0
numpy>=1.24.0
opencv-python-headless>=4.8.0""")

    w(f"{base}/.env.example", "GOOGLE_API_KEY=Put_Your_Key_Here")

    # 2. DOCKER (Hybrid Ready)
    w(f"{base}/Dockerfile", r"""
FROM python:3.11-slim
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc libgl1 libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN useradd -m -u 1000 appuser
COPY . .
RUN chown -R appuser:appuser /app
USER appuser
CMD ["python", "main.py"]
""")
    
    w(f"{base}/.dockerignore", "__pycache__\n*.pyc\n.env\n.git\n.gitignore\ntemp_input\nodnowione_final")

    # 3. CORE CONFIG (UPDATED TO GEMINI 3)
    w(f"{base}/src/__init__.py", "")
    w(f"{base}/src/config.py", r"""
import os
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.environ.get("GOOGLE_API_KEY")
if not API_KEY: print("WARN: No API Key found. AI features will fail, falling back to local."); 
# Updated to Gemini 3 as requested
MODEL_DETECTION = "models/gemini-3-pro-preview"
MODEL_RESTORATION = "models/gemini-3-pro-image-preview"
MAX_WORKERS = 20
INPUT_ZIP = "zdjecia.zip"
OUTPUT_DIR = "odnowione_final"
TEMP_DIR = "temp_input"
""")

    # 4. UTILS
    w(f"{base}/src/utils.py", r"""
import time, random, io, base64, requests
from PIL import Image

def encode_image_optimized(path, max_size=3500, quality=93):
    with Image.open(path) as img:
        if img.mode != "RGB": img = img.convert("RGB")
        if max(img.size) > max_size: img.thumbnail((max_size, max_size))
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=quality)
        return base64.b64encode(buf.getvalue()).decode('utf-8')

def make_request_with_retry(url, json_payload, headers, max_retries=5):
    if not headers.get("x-goog-api-key"): return None
    for i in range(max_retries):
        try:
            r = requests.post(url, json=json_payload, headers=headers, timeout=600)
            if r.status_code == 404: 
                if "v1beta" in url: 
                    url = url.replace("v1beta", "v1alpha")
                    continue
                return r
            if r.status_code in [429, 500, 503]:
                time.sleep((i + 1) * 2)
                continue
            return r
        except: time.sleep(1)
    return None
""")

    # 5. GRAPHICS
    w(f"{base}/src/graphics.py", r"""
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageChops

def aggressive_trim_borders(img):
    try:
        bg = Image.new(img.mode, img.size, img.getpixel((0,0)))
        diff = ImageChops.difference(img, bg)
        diff = ImageChops.add(diff, diff, 2.0, -100)
        bbox = diff.getbbox()
        if bbox and (bbox[2]-bbox[0]) > 50 and (bbox[3]-bbox[1]) > 50: return img.crop(bbox)
    except: pass
    return img

def apply_super_sharpen(img):
    img = ImageEnhance.Sharpness(img).enhance(1.4)
    img = img.filter(ImageFilter.UnsharpMask(radius=2, percent=140, threshold=3))
    return img

def warp_perspective(img, corners):
    def find_coeffs(pa, pb):
        matrix = []
        for p1, p2 in zip(pa, pb):
            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p1[0]*p2[0], -p1[0]*p2[1]])
            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p1[1]*p2[0], -p1[1]*p2[1]])
        A = np.matrix(matrix, dtype=float)
        B = np.array(pb).reshape(8)
        try: return np.array(np.dot(np.linalg.inv(A.T * A) * A.T, B)).reshape(8)
        except: return None

    pts = np.array(corners, dtype="float32")
    if len(pts) != 4: return None
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1)
    tl, br = pts[np.argmin(s)], pts[np.argmax(s)]
    tr, bl = pts[np.argmin(diff)], pts[np.argmax(diff)]
    wA = np.sqrt(((br[0]-bl[0])**2) + ((br[1]-bl[1])**2))
    wB = np.sqrt(((tr[0]-tl[0])**2) + ((tr[1]-tl[1])**2))
    mw = max(int(wA), int(wB))
    hA = np.sqrt(((tr[0]-br[0])**2) + ((tr[1]-br[1])**2))
    hB = np.sqrt(((tl[0]-bl[0])**2) + ((tl[1]-bl[1])**2))
    mh = max(int(hA), int(hB))
    coeffs = find_coeffs([(0,0), (mw,0), (mw,mh), (0,mh)], [(tl[0],tl[1]), (tr[0],tr[1]), (br[0],br[1]), (bl[0],bl[1])])
    if coeffs is not None: return img.transform((mw, mh), Image.PERSPECTIVE, coeffs, Image.BICUBIC)
    return img
""")

    # 6. AI CORE
    w(f"{base}/src/ai_core.py", r"""
import json, re, io, base64, cv2
import numpy as np
from PIL import Image
from src.config import API_KEY, MODEL_DETECTION, MODEL_RESTORATION
from src.utils import make_request_with_retry, encode_image_optimized
from src.graphics import aggressive_trim_borders, apply_super_sharpen

def get_url(m): return f"https://generativelanguage.googleapis.com/v1beta/models/{m.replace('models/','')}:generateContent"

def clean_json_response(text):
    try:
        return json.loads(re.sub(r"```json|```", "", text).strip())
    except: return None

def restore_locally(pil_img, save_path):
    try:
        cv_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        denoised = cv2.fastNlMeansDenoisingColored(cv_img, None, 10, 10, 7, 21)
        detail = cv2.detailEnhance(denoised, sigma_s=10, sigma_r=0.15)
        final_pil = Image.fromarray(cv2.cvtColor(detail, cv2.COLOR_BGR2RGB))
        final_pil = apply_super_sharpen(aggressive_trim_borders(final_pil))
        final_pil.save(save_path)
        return True
    except Exception as e:
        print(f"Local restore failed: {e}")
        return False

def detect_rotation_strict(path):
    url = get_url(MODEL_DETECTION)
    try:
        with Image.open(path) as img:
            img.thumbnail((800,800))
            buf=io.BytesIO(); img.save(buf,format="JPEG"); b64=base64.b64encode(buf.getvalue()).decode('utf-8')
        p = 'Look at people. Task: Direction of TOP OF HEADS? Options: "UP","DOWN","LEFT","RIGHT". JSON: {"direction": "UP"}'
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"responseMimeType":"application/json"}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        if r and r.status_code==200:
            j = clean_json_response(r.json()["candidates"][0]["content"]["parts"][0]["text"])
            if j: return {"UP":0, "DOWN":180, "RIGHT":90, "LEFT":270}.get(j.get("direction","UP"), 0)
    except: pass
    return 0

def detect_corners(path):
    url = get_url(MODEL_DETECTION)
    try:
        b64 = encode_image_optimized(path, 1500)
        p = 'Analyze scan. Detect 4 EXACT CORNERS. JSON: {"photos": [{"corners":[[x,y],[x,y],[x,y],[x,y]]}]}. Scale 0-1000.'
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"responseMimeType":"application/json"}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        if r and r.status_code==200:
            return clean_json_response(r.json()["candidates"][0]["content"]["parts"][0]["text"])
    except: pass
    return None

def restore_final(path, out):
    # Phase 1: Try AI (Gemini 3)
    url = get_url(MODEL_RESTORATION)
    try:
        b64 = encode_image_optimized(path, 4000)
        p = "Restore photo: Fix geometry, remove dust, sharpen faces. Return IMAGE."
        r = make_request_with_retry(url, {"contents":[{"parts":[{"text":p},{"inlineData":{"mimeType":"image/jpeg","data":b64}}]}],"generationConfig":{"temperature":0.35}}, {"Content-Type":"application/json","x-goog-api-key":API_KEY})
        
        if r and r.status_code==200:
            data = r.json()
            if "candidates" in data:
                parts = data["candidates"][0]["content"]["parts"]
                for x in parts:
                    if "inlineData" in x:
                        img = Image.open(io.BytesIO(base64.b64decode(x["inlineData"]["data"])))
                        img = apply_super_sharpen(aggressive_trim_borders(img))
                        img.save(out)
                        print("AI Restore SUCCESS")
                        return True
    except: pass
    
    # Phase 2: Local Fallback
    try:
        with Image.open(path) as img:
            return restore_locally(img, out)
    except: return False
""")

    # 7. WORKFLOW
    w(f"{base}/src/workflow.py", r"""
import os, random
from PIL import Image
from src.config import OUTPUT_DIR
from src.ai_core import detect_rotation_strict, detect_corners, restore_final
from src.graphics import warp_perspective

def process(fpath, fname):
    log = []
    temps = []
    try:
        ang = detect_rotation_strict(fpath)
        cur = fpath
        if ang != 0:
            cur = f"tmp_rot_{random.randint(111,999)}_{fname}"
            Image.open(fpath).rotate(ang, expand=True).save(cur)
            temps.append(cur)
        
        data = detect_corners(cur)
        parts = []
        if data and "photos" in data:
            img = Image.open(cur).convert("RGB")
            w, h = img.size
            for i, item in enumerate(data["photos"]):
                try:
                    px = [[(p[0]/1000)*w, (p[1]/1000)*h] for p in item["corners"]]
                    s = warp_perspective(img, px)
                    if s:
                        n = f"tmp_cut_{i}_{fname}"
                        s.save(n, quality=95)
                        parts.append(n); temps.append(n)
                except: pass
        if not parts: parts.append(cur)
        
        for i, p in enumerate(parts):
            suf = f"_{i+1}" if len(parts)>1 else ""
            out = os.path.join(OUTPUT_DIR, f"restored_{os.path.splitext(fname)[0]}{suf}.png")
            if os.path.exists(out): log.append(f"SKIP: {out}"); continue
            
            print(f">> Processing {fname} part {i+1}")
            if restore_final(p, out): log.append(f"OK: {out}")
            else: log.append(f"ERR: {fname}")
            
    except Exception as e: log.append(f"CRASH {fname}: {e}")
    finally:
        for t in temps: 
            if os.path.exists(t): 
                try: os.remove(t)
                except: pass
    return log
""")

    # 8. MAIN
    w(f"{base}/main.py", r"""
import os, zipfile, shutil, concurrent.futures
from src.config import INPUT_ZIP, OUTPUT_DIR, TEMP_DIR, MAX_WORKERS
from src.workflow import process

if __name__ == "__main__":
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
    os.makedirs(TEMP_DIR)
    
    if not os.path.exists(INPUT_ZIP): print(f"No zip found: {INPUT_ZIP}"); exit()
    with zipfile.ZipFile(INPUT_ZIP,'r') as z: z.extractall(TEMP_DIR)
    
    fs = [os.path.join(r,f) for r,_,x in os.walk(TEMP_DIR) for f in x if f.lower().endswith(('jpg','png','jpeg'))]
    print(f"Start: {len(fs)} files, {MAX_WORKERS} threads.")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        ft = {ex.submit(process, f, os.path.basename(f)):f for f in fs}
        for f in concurrent.futures.as_completed(ft):
            for l in f.result(): print(l)
            
    try: shutil.rmtree(TEMP_DIR)
    except: pass
    print("DONE.")
""")

    print(f"\n[+] Hybrid System V7 (Gemini 3) Installed in '{base}'.\nRun 'run.bat' to rebuild.")

if __name__ == "__main__":
    main()